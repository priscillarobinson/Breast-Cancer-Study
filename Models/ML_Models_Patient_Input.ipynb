{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd49c703",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4a350",
   "metadata": {},
   "source": [
    "### The models utilize 19 clinical attributes to predict breast cancer survival\n",
    "#### The Models used were Logistic Regression, Support Vector Classification, Random Forest Classifier, AdaBoost classifier, and XGBoost Classifier\n",
    "\n",
    "#### The Random Forest Classifier produced the strongest accuracy at 0.696\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec694900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd73923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_at_diagnosis</th>\n",
       "      <th>chemotherapy</th>\n",
       "      <th>neoplasm_histologic_grade</th>\n",
       "      <th>hormone_therapy</th>\n",
       "      <th>lymph_nodes_examined_positive</th>\n",
       "      <th>mutation_count</th>\n",
       "      <th>overall_survival</th>\n",
       "      <th>radio_therapy</th>\n",
       "      <th>tumor_size</th>\n",
       "      <th>tumor_stage</th>\n",
       "      <th>encoded_type_of_breast_surgery</th>\n",
       "      <th>encoded_cancer_type_detailed</th>\n",
       "      <th>encoded_cellularity</th>\n",
       "      <th>encoded_pam50_+_claudin-low_subtype</th>\n",
       "      <th>encoded_er_status</th>\n",
       "      <th>encoded_her2_status</th>\n",
       "      <th>encoded_tumor_other_histologic_subtype</th>\n",
       "      <th>encoded_inferred_menopausal_state</th>\n",
       "      <th>encoded_integrative_cluster</th>\n",
       "      <th>encoded_pr_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.87</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.68</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.97</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.77</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.45</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84.22</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85.49</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70.91</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>66.91</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>62.62</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45.43</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52.14</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>61.49</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>51.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50.42</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>49.61</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64.85</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>43.55</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78.19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>68.68</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46.89</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>51.38</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>49.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>65.59</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>43.15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>54.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>83.89</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>48.59</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>39.84</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>42.55</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>82.73</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>72.10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>78.73</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>58.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43.46</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>73.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>52.11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>57.40</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>69.16</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>58.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>73.11</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>72.30</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>51.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>47.62</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>74.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>62.40</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>79.28</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>53.16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age_at_diagnosis  chemotherapy  neoplasm_histologic_grade  \\\n",
       "1              43.19             0                        3.0   \n",
       "2              48.87             1                        2.0   \n",
       "3              47.68             1                        2.0   \n",
       "4              76.97             1                        3.0   \n",
       "5              78.77             0                        3.0   \n",
       "6              56.45             1                        2.0   \n",
       "7              84.22             0                        2.0   \n",
       "8              85.49             0                        2.0   \n",
       "9              70.91             0                        1.0   \n",
       "14             66.91             0                        3.0   \n",
       "15             62.62             0                        2.0   \n",
       "16             45.43             1                        3.0   \n",
       "17             52.14             1                        3.0   \n",
       "19             61.49             0                        2.0   \n",
       "20             51.01             0                        1.0   \n",
       "21             50.42             1                        3.0   \n",
       "22             49.61             0                        2.0   \n",
       "23             64.85             0                        2.0   \n",
       "24             43.55             0                        3.0   \n",
       "25             78.19             0                        3.0   \n",
       "26             68.68             1                        3.0   \n",
       "27             46.89             0                        2.0   \n",
       "28             51.38             1                        2.0   \n",
       "29             49.87             1                        1.0   \n",
       "30             65.59             0                        3.0   \n",
       "31             43.15             1                        3.0   \n",
       "32             54.23             0                        1.0   \n",
       "33             83.89             0                        3.0   \n",
       "35             48.59             0                        2.0   \n",
       "36             39.84             1                        3.0   \n",
       "37             42.55             1                        2.0   \n",
       "38             60.07             0                        2.0   \n",
       "39             82.73             0                        2.0   \n",
       "40             72.10             0                        3.0   \n",
       "41             78.73             0                        2.0   \n",
       "42             58.95             0                        1.0   \n",
       "43             43.46             1                        2.0   \n",
       "44             73.98             0                        1.0   \n",
       "46             52.11             1                        2.0   \n",
       "47             57.40             0                        2.0   \n",
       "49             69.16             1                        3.0   \n",
       "50             58.89             1                        1.0   \n",
       "51             73.11             0                        3.0   \n",
       "53             72.30             0                        2.0   \n",
       "54             51.33             0                        2.0   \n",
       "55             47.62             0                        2.0   \n",
       "56             74.07             0                        2.0   \n",
       "59             62.40             0                        2.0   \n",
       "60             79.28             0                        2.0   \n",
       "61             53.16             0                        3.0   \n",
       "\n",
       "    hormone_therapy  lymph_nodes_examined_positive  mutation_count  \\\n",
       "1                 1                              0             2.0   \n",
       "2                 1                              1             2.0   \n",
       "3                 1                              3             1.0   \n",
       "4                 1                              8             2.0   \n",
       "5                 1                              0             4.0   \n",
       "6                 1                              1             4.0   \n",
       "7                 0                              0             5.0   \n",
       "8                 1                              0             1.0   \n",
       "9                 1                              0             3.0   \n",
       "14                1                              0             3.0   \n",
       "15                1                              0             4.0   \n",
       "16                1                              0             5.0   \n",
       "17                0                              0             3.0   \n",
       "19                1                              1             3.0   \n",
       "20                1                              1             2.0   \n",
       "21                0                              4             4.0   \n",
       "22                1                              0             4.0   \n",
       "23                1                              0             2.0   \n",
       "24                1                              1             4.0   \n",
       "25                1                              3             2.0   \n",
       "26                0                              0             1.0   \n",
       "27                1                              0             3.0   \n",
       "28                1                             16             4.0   \n",
       "29                1                              5             4.0   \n",
       "30                1                              0             4.0   \n",
       "31                1                              0             2.0   \n",
       "32                1                              0             4.0   \n",
       "33                1                             14             8.0   \n",
       "35                1                              0             3.0   \n",
       "36                0                              0             5.0   \n",
       "37                1                              1             2.0   \n",
       "38                1                              1             2.0   \n",
       "39                1                              1             2.0   \n",
       "40                1                              1             3.0   \n",
       "41                1                              6             4.0   \n",
       "42                1                              1             5.0   \n",
       "43                1                              2             1.0   \n",
       "44                1                              0             3.0   \n",
       "46                1                              1             5.0   \n",
       "47                1                              0             4.0   \n",
       "49                1                              0             5.0   \n",
       "50                1                              1             3.0   \n",
       "51                1                              3             1.0   \n",
       "53                1                              0             2.0   \n",
       "54                1                              0             2.0   \n",
       "55                1                              1             1.0   \n",
       "56                1                              1             1.0   \n",
       "59                1                              0             2.0   \n",
       "60                1                              9             2.0   \n",
       "61                0                              0             3.0   \n",
       "\n",
       "    overall_survival  radio_therapy  tumor_size  tumor_stage  \\\n",
       "1                  1              1        10.0          1.0   \n",
       "2                  0              0        15.0          2.0   \n",
       "3                  1              1        25.0          2.0   \n",
       "4                  0              1        40.0          2.0   \n",
       "5                  0              1        31.0          4.0   \n",
       "6                  1              1        10.0          2.0   \n",
       "7                  0              0        28.0          2.0   \n",
       "8                  0              1        22.0          4.0   \n",
       "9                  1              1        21.0          1.0   \n",
       "14                 1              1        36.0          2.0   \n",
       "15                 1              0        29.0          1.0   \n",
       "16                 1              1        23.0          2.0   \n",
       "17                 1              1        17.0          1.0   \n",
       "19                 1              1        16.0          2.0   \n",
       "20                 1              1        12.0          2.0   \n",
       "21                 0              1        40.0          2.0   \n",
       "22                 1              1        24.0          2.0   \n",
       "23                 0              1        13.0          1.0   \n",
       "24                 1              1        14.0          2.0   \n",
       "25                 1              1        30.0          2.0   \n",
       "26                 0              1        39.0          2.0   \n",
       "27                 1              1        34.0          2.0   \n",
       "28                 0              1        40.0          2.0   \n",
       "29                 1              1        70.0          3.0   \n",
       "30                 1              0        18.0          2.0   \n",
       "31                 0              1        18.0          1.0   \n",
       "32                 1              0        27.0          2.0   \n",
       "33                 0              1       150.0          3.0   \n",
       "35                 1              0        30.0          2.0   \n",
       "36                 0              1        25.0          2.0   \n",
       "37                 1              1        60.0          3.0   \n",
       "38                 1              1        23.0          2.0   \n",
       "39                 0              1        23.0          2.0   \n",
       "40                 0              1        26.0          2.0   \n",
       "41                 1              1        30.0          2.0   \n",
       "42                 1              1        20.0          2.0   \n",
       "43                 1              1        50.0          3.0   \n",
       "44                 1              0         9.0          2.0   \n",
       "46                 1              1        13.0          2.0   \n",
       "47                 1              1        14.0          1.0   \n",
       "49                 0              1        39.0          2.0   \n",
       "50                 1              1        80.0          2.0   \n",
       "51                 0              1        22.0          2.0   \n",
       "53                 1              0        13.0          1.0   \n",
       "54                 1              0        18.0          1.0   \n",
       "55                 1              1        30.0          2.0   \n",
       "56                 1              1        27.0          2.0   \n",
       "59                 1              1        20.0          1.0   \n",
       "60                 0              1        38.0          2.0   \n",
       "61                 1              0        19.0          1.0   \n",
       "\n",
       "    encoded_type_of_breast_surgery  encoded_cancer_type_detailed  \\\n",
       "1                                0                             1   \n",
       "2                                1                             1   \n",
       "3                                1                             4   \n",
       "4                                1                             4   \n",
       "5                                1                             1   \n",
       "6                                0                             1   \n",
       "7                                1                             2   \n",
       "8                                1                             1   \n",
       "9                                0                             1   \n",
       "14                               1                             1   \n",
       "15                               1                             4   \n",
       "16                               0                             1   \n",
       "17                               1                             1   \n",
       "19                               0                             1   \n",
       "20                               0                             1   \n",
       "21                               1                             1   \n",
       "22                               0                             1   \n",
       "23                               0                             2   \n",
       "24                               0                             4   \n",
       "25                               1                             1   \n",
       "26                               1                             1   \n",
       "27                               1                             2   \n",
       "28                               1                             2   \n",
       "29                               1                             1   \n",
       "30                               1                             1   \n",
       "31                               0                             1   \n",
       "32                               1                             1   \n",
       "33                               1                             2   \n",
       "35                               1                             1   \n",
       "36                               1                             1   \n",
       "37                               1                             2   \n",
       "38                               0                             4   \n",
       "39                               1                             1   \n",
       "40                               1                             1   \n",
       "41                               1                             1   \n",
       "42                               0                             1   \n",
       "43                               0                             4   \n",
       "44                               0                             4   \n",
       "46                               0                             1   \n",
       "47                               0                             1   \n",
       "49                               1                             1   \n",
       "50                               0                             4   \n",
       "51                               1                             1   \n",
       "53                               0                             1   \n",
       "54                               0                             1   \n",
       "55                               0                             2   \n",
       "56                               0                             1   \n",
       "59                               0                             2   \n",
       "60                               1                             2   \n",
       "61                               1                             1   \n",
       "\n",
       "    encoded_cellularity  encoded_pam50_+_claudin-low_subtype  \\\n",
       "1                     0                                    2   \n",
       "2                     0                                    3   \n",
       "3                     2                                    3   \n",
       "4                     0                                    3   \n",
       "5                     2                                    3   \n",
       "6                     2                                    3   \n",
       "7                     0                                    1   \n",
       "8                     2                                    2   \n",
       "9                     0                                    3   \n",
       "14                    2                                    3   \n",
       "15                    0                                    3   \n",
       "16                    0                                    3   \n",
       "17                    0                                    0   \n",
       "19                    0                                    3   \n",
       "20                    0                                    2   \n",
       "21                    0                                    1   \n",
       "22                    2                                    6   \n",
       "23                    2                                    3   \n",
       "24                    0                                    3   \n",
       "25                    0                                    2   \n",
       "26                    1                                    0   \n",
       "27                    2                                    5   \n",
       "28                    0                                    3   \n",
       "29                    2                                    2   \n",
       "30                    2                                    3   \n",
       "31                    1                                    6   \n",
       "32                    0                                    2   \n",
       "33                    0                                    2   \n",
       "35                    1                                    2   \n",
       "36                    2                                    0   \n",
       "37                    2                                    5   \n",
       "38                    2                                    2   \n",
       "39                    0                                    3   \n",
       "40                    2                                    3   \n",
       "41                    2                                    2   \n",
       "42                    2                                    2   \n",
       "43                    1                                    2   \n",
       "44                    1                                    3   \n",
       "46                    3                                    5   \n",
       "47                    1                                    6   \n",
       "49                    2                                    2   \n",
       "50                    2                                    2   \n",
       "51                    0                                    3   \n",
       "53                    0                                    2   \n",
       "54                    2                                    2   \n",
       "55                    2                                    2   \n",
       "56                    0                                    3   \n",
       "59                    2                                    2   \n",
       "60                    0                                    2   \n",
       "61                    0                                    1   \n",
       "\n",
       "    encoded_er_status  encoded_her2_status  \\\n",
       "1                   1                    0   \n",
       "2                   1                    0   \n",
       "3                   1                    0   \n",
       "4                   1                    0   \n",
       "5                   1                    0   \n",
       "6                   1                    0   \n",
       "7                   1                    0   \n",
       "8                   1                    0   \n",
       "9                   1                    0   \n",
       "14                  1                    0   \n",
       "15                  1                    0   \n",
       "16                  1                    0   \n",
       "17                  0                    0   \n",
       "19                  1                    0   \n",
       "20                  1                    0   \n",
       "21                  0                    0   \n",
       "22                  1                    0   \n",
       "23                  1                    0   \n",
       "24                  1                    0   \n",
       "25                  1                    0   \n",
       "26                  0                    0   \n",
       "27                  1                    0   \n",
       "28                  1                    0   \n",
       "29                  1                    0   \n",
       "30                  1                    0   \n",
       "31                  1                    0   \n",
       "32                  1                    0   \n",
       "33                  1                    0   \n",
       "35                  1                    0   \n",
       "36                  0                    0   \n",
       "37                  1                    0   \n",
       "38                  1                    0   \n",
       "39                  1                    0   \n",
       "40                  1                    1   \n",
       "41                  1                    0   \n",
       "42                  1                    0   \n",
       "43                  1                    0   \n",
       "44                  1                    0   \n",
       "46                  0                    0   \n",
       "47                  1                    0   \n",
       "49                  1                    0   \n",
       "50                  1                    0   \n",
       "51                  1                    0   \n",
       "53                  1                    0   \n",
       "54                  1                    0   \n",
       "55                  1                    0   \n",
       "56                  1                    0   \n",
       "59                  1                    0   \n",
       "60                  1                    0   \n",
       "61                  0                    1   \n",
       "\n",
       "    encoded_tumor_other_histologic_subtype  encoded_inferred_menopausal_state  \\\n",
       "1                                        0                                  1   \n",
       "2                                        0                                  1   \n",
       "3                                        4                                  1   \n",
       "4                                        4                                  0   \n",
       "5                                        0                                  0   \n",
       "6                                        0                                  0   \n",
       "7                                        1                                  0   \n",
       "8                                        0                                  0   \n",
       "9                                        0                                  0   \n",
       "14                                       0                                  0   \n",
       "15                                       4                                  0   \n",
       "16                                       0                                  1   \n",
       "17                                       0                                  0   \n",
       "19                                       0                                  0   \n",
       "20                                       7                                  0   \n",
       "21                                       0                                  0   \n",
       "22                                       0                                  1   \n",
       "23                                       1                                  0   \n",
       "24                                       4                                  1   \n",
       "25                                       0                                  0   \n",
       "26                                       0                                  0   \n",
       "27                                       1                                  1   \n",
       "28                                       1                                  0   \n",
       "29                                       0                                  1   \n",
       "30                                       0                                  0   \n",
       "31                                       0                                  1   \n",
       "32                                       0                                  0   \n",
       "33                                       1                                  0   \n",
       "35                                       0                                  1   \n",
       "36                                       0                                  1   \n",
       "37                                       1                                  1   \n",
       "38                                       4                                  0   \n",
       "39                                       0                                  0   \n",
       "40                                       0                                  0   \n",
       "41                                       0                                  0   \n",
       "42                                       0                                  0   \n",
       "43                                       4                                  1   \n",
       "44                                       4                                  0   \n",
       "46                                       0                                  0   \n",
       "47                                       0                                  0   \n",
       "49                                       0                                  0   \n",
       "50                                       4                                  0   \n",
       "51                                       0                                  0   \n",
       "53                                       0                                  0   \n",
       "54                                       0                                  0   \n",
       "55                                       1                                  1   \n",
       "56                                       0                                  0   \n",
       "59                                       1                                  0   \n",
       "60                                       1                                  0   \n",
       "61                                       0                                  0   \n",
       "\n",
       "    encoded_integrative_cluster  encoded_pr_status  \n",
       "1                             4                  1  \n",
       "2                             3                  1  \n",
       "3                            10                  1  \n",
       "4                            10                  1  \n",
       "5                             8                  1  \n",
       "6                             3                  1  \n",
       "7                             3                  0  \n",
       "8                             3                  1  \n",
       "9                             4                  1  \n",
       "14                            1                  1  \n",
       "15                            0                  1  \n",
       "16                            1                  1  \n",
       "17                            1                  0  \n",
       "19                            8                  1  \n",
       "20                            3                  1  \n",
       "21                            1                  0  \n",
       "22                            3                  1  \n",
       "23                            2                  1  \n",
       "24                            3                  1  \n",
       "25                            9                  1  \n",
       "26                            1                  0  \n",
       "27                            9                  1  \n",
       "28                            3                  1  \n",
       "29                            9                  1  \n",
       "30                            0                  1  \n",
       "31                            4                  0  \n",
       "32                            3                  1  \n",
       "33                            3                  0  \n",
       "35                            9                  1  \n",
       "36                            1                  0  \n",
       "37                            7                  1  \n",
       "38                            0                  0  \n",
       "39                            8                  0  \n",
       "40                           10                  0  \n",
       "41                            9                  0  \n",
       "42                            9                  1  \n",
       "43                            9                  1  \n",
       "44                            9                  1  \n",
       "46                            3                  0  \n",
       "47                            3                  1  \n",
       "49                            9                  0  \n",
       "50                            9                  0  \n",
       "51                            9                  0  \n",
       "53                            3                  1  \n",
       "54                            3                  1  \n",
       "55                            3                  1  \n",
       "56                            9                  0  \n",
       "59                            3                  1  \n",
       "60                            2                  1  \n",
       "61                            6                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file into a pandas DataFrame\n",
    "df = pd.read_csv('../Data/df_clinical_survival_ML.csv')\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e78964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_at_diagnosis', 'chemotherapy', 'neoplasm_histologic_grade',\n",
       "       'hormone_therapy', 'lymph_nodes_examined_positive', 'mutation_count',\n",
       "       'overall_survival', 'radio_therapy', 'tumor_size', 'tumor_stage',\n",
       "       'encoded_type_of_breast_surgery', 'encoded_cancer_type_detailed',\n",
       "       'encoded_cellularity', 'encoded_pam50_+_claudin-low_subtype',\n",
       "       'encoded_er_status', 'encoded_her2_status',\n",
       "       'encoded_tumor_other_histologic_subtype',\n",
       "       'encoded_inferred_menopausal_state', 'encoded_integrative_cluster',\n",
       "       'encoded_pr_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7fdfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['age_at_diagnosis', 'chemotherapy',\n",
    "       'hormone_therapy','overall_survival', 'radio_therapy',\n",
    "       'tumor_size', 'tumor_stage','encoded_type_of_breast_surgery',\n",
    "       'encoded_cancer_type_detailed',\n",
    "#        'encoded_er_status', 'encoded_her2_status',\n",
    "       'encoded_inferred_menopausal_state'\n",
    "#        ,'encoded_pr_status'\n",
    "      ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abbfe608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold \n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b72340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. Utilized as x values.\n",
    "selected_features = df.drop(['overall_survival'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab70833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 9) (1017,)\n"
     ]
    }
   ],
   "source": [
    "# Set X and y variables\n",
    "y = df['overall_survival']\n",
    "X = selected_features\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd53107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, cross_val_predict,  KFold\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b9777e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_at_diagnosis</th>\n",
       "      <th>chemotherapy</th>\n",
       "      <th>hormone_therapy</th>\n",
       "      <th>radio_therapy</th>\n",
       "      <th>tumor_size</th>\n",
       "      <th>tumor_stage</th>\n",
       "      <th>encoded_type_of_breast_surgery</th>\n",
       "      <th>encoded_cancer_type_detailed</th>\n",
       "      <th>encoded_inferred_menopausal_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>51.74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>68.93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>81.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>52.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>51.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_at_diagnosis  chemotherapy  hormone_therapy  radio_therapy  \\\n",
       "196              51.74             0                1              0   \n",
       "997              68.93             0                1              0   \n",
       "1028             81.57             0                1              0   \n",
       "407              52.98             0                0              1   \n",
       "1052             51.25             1                1              1   \n",
       "\n",
       "      tumor_size  tumor_stage  encoded_type_of_breast_surgery  \\\n",
       "196         22.0          2.0                               1   \n",
       "997         18.0          2.0                               1   \n",
       "1028        35.0          2.0                               1   \n",
       "407         10.0          1.0                               0   \n",
       "1052        25.0          2.0                               1   \n",
       "\n",
       "      encoded_cancer_type_detailed  encoded_inferred_menopausal_state  \n",
       "196                              4                                  0  \n",
       "997                              1                                  0  \n",
       "1028                             1                                  0  \n",
       "407                              1                                  0  \n",
       "1052                             1                                  0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bc10cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "#Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bbfa713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
      " 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "113d33b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6509186351706037\n",
      "Testing Data Score: 0.6039215686274509\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c3d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.41      0.47       111\n",
      "           0       0.62      0.76      0.68       144\n",
      "\n",
      "    accuracy                           0.60       255\n",
      "   macro avg       0.59      0.58      0.58       255\n",
      "weighted avg       0.60      0.60      0.59       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions, \n",
    "                            target_names = [\"1\", \"0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ec1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [10, 50, 100],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'max_iter': [200,500,800],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4c5a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5] END C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=10, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=10, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=10, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=10, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=10, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=10, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=10, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=10, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=10, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=10, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=10, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=10, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=10, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=10, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=10, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=10, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=10, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=50, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=50, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=50, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=50, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=50, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=50, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=50, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=50, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=50, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=50, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=50, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=50, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=50, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=50, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=50, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=50, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=50, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=50, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=50, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=50, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=50, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=50, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=50, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=50, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=50, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=50, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=50, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...C=50, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...C=50, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...C=50, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...C=50, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...C=50, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=50, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=50, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=50, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=50, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=50, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=200, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..C=100, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..C=100, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..C=100, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..C=100, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..C=100, max_iter=200, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=500, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..C=100, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..C=100, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..C=100, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..C=100, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..C=100, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=800, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..C=100, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..C=100, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..C=100, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..C=100, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..C=100, max_iter=800, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=800, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..C=100, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..C=100, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..C=100, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..C=100, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..C=100, max_iter=800, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=800, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\nick\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.63390953 0.63390953 0.63390953 0.63390953\n",
      "        nan        nan 0.63390953 0.63390953 0.63390953 0.63390953\n",
      "        nan        nan 0.63390953 0.63390953 0.63390953 0.63390953\n",
      "        nan        nan 0.63522532 0.63522532 0.63522532 0.63522532\n",
      "        nan        nan 0.63522532 0.63522532 0.63522532 0.63522532\n",
      "        nan        nan 0.63522532 0.63522532 0.63522532 0.63522532\n",
      "        nan        nan 0.63522532 0.63522532 0.63522532 0.63522532\n",
      "        nan        nan 0.63522532 0.63522532 0.63522532 0.63522532\n",
      "        nan        nan 0.63522532 0.63522532 0.63522532 0.63522532]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=500),\n",
       "             param_grid={'C': [10, 50, 100], 'max_iter': [200, 500, 800],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4a360f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.6352253181974545\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccdb7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def model_metrics(model, kfold, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #metrics\n",
    "    results = cross_val_score(model, X_train, y_train, cv = kfold)\n",
    "    print(\"CV scores: \", results); print(\"CV Standard Deviation: \", results.std()); print();\n",
    "    print('CV Mean score: ', results.mean()); \n",
    "    print('Train score:   ', model.score(X_train, y_train))\n",
    "    print('Test score:    ', model.score(X_test, y_test))\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    print()\n",
    "    print('Confusion Matrix: ')\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "    print('Classification Report:  ')\n",
    "    print(classification_report(y_test, pred))\n",
    "    train_score =  model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred, test_score, results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be8bbde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.58823529 0.67973856 0.57236842 0.63157895 0.67763158]\n",
      "CV Standard Deviation:  0.044296353121267514\n",
      "\n",
      "CV Mean score:  0.6299105607155142\n",
      "Train score:    0.6430446194225722\n",
      "Test score:     0.6\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 44  67]\n",
      " [ 35 109]]\n",
      "Classification Report:  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.40      0.46       111\n",
      "           1       0.62      0.76      0.68       144\n",
      "\n",
      "    accuracy                           0.60       255\n",
      "   macro avg       0.59      0.58      0.57       255\n",
      "weighted avg       0.59      0.60      0.59       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "    \n",
    "lr_params = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": np.logspace(-2,4,100)\n",
    "    }\n",
    "logistic_regression = GridSearchCV(LogisticRegression(random_state=42), param_grid=lr_params, n_jobs=-1, cv=4)\n",
    "lg_pred, lg_test, lg_train = model_metrics(logistic_regression, kfold, X_train, X_test, y_train.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0387298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.60130719 0.62745098 0.59868421 0.64473684 0.66447368]\n",
      "CV Standard Deviation:  0.02522076121790435\n",
      "\n",
      "CV Mean score:  0.6273305813553491\n",
      "Train score:    0.6876640419947506\n",
      "Test score:     0.6196078431372549\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 54  57]\n",
      " [ 40 104]]\n",
      "Classification Report:  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.49      0.53       111\n",
      "           1       0.65      0.72      0.68       144\n",
      "\n",
      "    accuracy                           0.62       255\n",
      "   macro avg       0.61      0.60      0.60       255\n",
      "weighted avg       0.61      0.62      0.61       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVC Model import and use\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(random_state=42)\n",
    "svc_pred, svc_test, svc_train = model_metrics(svc, kfold, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9f14afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.61437908 0.61437908 0.59210526 0.65131579 0.68421053]\n",
      "CV Standard Deviation:  0.03258531976033108\n",
      "\n",
      "CV Mean score:  0.6312779497764017\n",
      "Train score:    0.6955380577427821\n",
      "Test score:     0.6196078431372549\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 54  57]\n",
      " [ 40 104]]\n",
      "Classification Report:  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.49      0.53       111\n",
      "           1       0.65      0.72      0.68       144\n",
      "\n",
      "    accuracy                           0.62       255\n",
      "   macro avg       0.61      0.60      0.60       255\n",
      "weighted avg       0.61      0.62      0.61       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost model import and use\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_boost = AdaBoostClassifier(random_state=42)\n",
    "ab_pred, ab_test, ab_train = model_metrics(ada_boost, kfold, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c532d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.5751634  0.67973856 0.61184211 0.63815789 0.60526316]\n",
      "CV Standard Deviation:  0.03513341882890285\n",
      "\n",
      "CV Mean score:  0.62203302373581\n",
      "Train score:    0.9986876640419947\n",
      "Test score:     0.592156862745098\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 54]\n",
      " [50 94]]\n",
      "Classification Report:  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52       111\n",
      "           1       0.64      0.65      0.64       144\n",
      "\n",
      "    accuracy                           0.59       255\n",
      "   macro avg       0.58      0.58      0.58       255\n",
      "weighted avg       0.59      0.59      0.59       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RandomForest Model import and use\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "rf_pred, rf_test, rf_train = model_metrics(random_forest, kfold, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f64e9395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7 , 0.3 ],\n",
       "       [0.71, 0.29],\n",
       "       [0.76, 0.24],\n",
       "       ...,\n",
       "       [0.89, 0.11],\n",
       "       [0.71, 0.29],\n",
       "       [0.84, 0.16]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5adbaae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 0.021 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "importances = random_forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67e033d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4331142998362242, 'age_at_diagnosis'),\n",
       " (0.2836394201737549, 'tumor_size'),\n",
       " (0.06233748423166784, 'tumor_stage'),\n",
       " (0.04903127727530473, 'encoded_cancer_type_detailed'),\n",
       " (0.04239478789546689, 'hormone_therapy'),\n",
       " (0.04207018773884366, 'encoded_type_of_breast_surgery'),\n",
       " (0.03591802247165952, 'radio_therapy'),\n",
       " (0.030680888792148156, 'chemotherapy'),\n",
       " (0.02081363158493017, 'encoded_inferred_menopausal_state')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = random_forest.feature_importances_\n",
    "sorted(zip(random_forest.feature_importances_,selected_features.columns),reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "246f06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [c for c in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abeed94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "054f08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving RandomForest Model for use as it produced strongest accuracy\n",
    "# import joblib\n",
    "# filename = 'randomForest_model.pkl'\n",
    "# joblib.dump(random_forest, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "748ac41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Testing loading the model back in\n",
    "# rfm = joblib.load('randomForest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4b827a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Simply test of loaded saved model\n",
    "# rfm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8881a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import XGB and use\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe70193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nick\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nick\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\nick\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aedd5990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:39:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CV scores:  [0.59477124 0.62091503 0.61842105 0.61184211 0.61842105]\n",
      "CV Standard Deviation:  0.009539103232606767\n",
      "\n",
      "CV Mean score:  0.612874097007224\n",
      "Train score:    0.9986876640419947\n",
      "Test score:     0.6274509803921569\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 43]\n",
      " [52 92]]\n",
      "Classification Report:  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59       111\n",
      "           1       0.68      0.64      0.66       144\n",
      "\n",
      "    accuracy                           0.63       255\n",
      "   macro avg       0.62      0.63      0.62       255\n",
      "weighted avg       0.63      0.63      0.63       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "clinical_xgb1_pred_, clinical_xgb1_test_score, clinical_xgb1_cv_score = model_metrics(xgb1, kfold, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c823cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
